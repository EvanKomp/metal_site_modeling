data:
  # data source
  source: "/datasets/alphafold_data/data_v2/pdb_mmcif/mmcif_files" # Source of data, e.g. "mfs", "cif", "pdb"
  # source: "./tmp/tmp_cifs"
  debug_max_files: null # Maximum number of sites to use for debugging

  # parsing metal binding sites
  remove_entities: ['SO4', 'PO4', 'CL', 'BR', 'I', 'NO3', 'ACT', 'FMT', 'TRS', 'BIC', 'TRA', 'MES', 'BIS', 'EPE', 'IMD', 'GOL', 'ETG', 'PEG', 'PG4', 'PGE', 'MPD', 'DMS', 'SUC', 'TRE', 'XYL', 'ERY', 'ACE', 'EOH', 'MOH', 'IPA', 'BUT', 'DMF', 'DMSO', 'LDA', 'OP1', 'C8E', 'DDM', 'BOG', 'LMT', 'IOD', 'XE', 'KR', 'BCB', 'BTB', 'CR', 'MB', 'UNX', 'UNL', 'UNK', 'DUM', 'AMS', 'LIS', 'CAS', 'MPO', 'NEP', 'PEN', 'HEX']
  skip_sites_with_entities:  null # list of entitiy names or 'non_metal', in which case if a site contains an antity that does not have a metal, it is skipped (other than water)
  backbone_treatment: free # one of 'ca_only', 'free', 'bound'. For ca_only, Cb , O, N are removed. for free, just the bond is broken. For bound, the bond and all atoms are kept.
  metal_aggregation_distance: 4 # Distance in Angstroms to aggregate metals into a single site
  metal_site_radius: 6 # Radius in Angstroms from metal to include entities in metal binding site
  max_atoms_per_site: 400 # Maximum number of heavy atoms to consider in a system
  coordination_distance: 2.9 # Distance in Angstroms to consider an atom as coordinating a metal
  min_coordinating_residues_per_site: 3 # Minimum number of residues coordinating the metal to consider a site valid
  min_residues_per_site: 3 # Minimum number of residues in a site to consider it valid
  max_water_bfactor: 18
  n_cores: 104

2_pretraining:
  # related to data filtering and processing
  data:
    debug_max_sites: null
    # filtering 1:1 with MetalSiteDataset filtering
    filtering:
      valid_metals: null
      min_metals: null
      max_metals: null
      min_organic_ligands: null
      max_organic_ligands: null
      min_waters: null
      max_waters: null
      min_nucleotides: null
      max_nucleotides: null
      min_amino_acids: 4
      max_amino_acids: null
      min_co_amino_acids: 2
      max_co_amino_acids: null
      min_sites_per_pdb: null
      max_sites_per_pdb: null
      max_unresolved_removed: 0
      max_resolution: 3.5
      max_max_rczd: null

    splitting:
      test_frac: 0.1
      val_frac_of_train: 0.05
      seed: 42

    # tokenization / collation
    tokenization:
      # should have 1:1 with MetalSiteCollator
      atom_features: ['element', 'charge', 'nhyd', 'hyb']
      bond_features: ['bond_order', 'is_in_ring', 'is_aromatic']
      k: 20 # graph size
      node_mlm_do: True
      node_mlm_rate: 0.15
      node_mlm_subrate_tweak: 0.0
      node_mlm_subrate_keep: 0.1

      # this is just here in case we want to train on slightly noised structures
      # its not expected that we will do full collapsing
      residue_collapse_do: False
      residue_collapse_rate: 0.0 # KEEP THIS AT 0.0, otherwise if the above is true, it will collapse whole residues
      residue_collapse_other_atom_noise_sigma: 0.1 # sigma of gaussian in angstroms to noise all atoms in system

      active_aggregators: ['unknown_metal']

    loss_weighting:
      cel_count_to_weight_temperature: 2.0
      cel_count_to_weight_clip_token: '<METAL>' # clip upweighting of any rarer tokens than this by this weight

  dataloader_n_processes: 8 # number of processes to use for data loading NOTE: Not used for training this is for getting dataset stats

  model:
    # should have 1:1 with EquiformerWEdgesConfig
    
    # === CORE ARCHITECTURE ===
    num_layers: 12
    sphere_channels: 128
    attn_hidden_channels: 64
    num_heads: 8
    attn_alpha_channels: 64
    attn_value_channels: 16
    ffn_hidden_channels: 128
    norm_type: "layer_norm_sh"
    lmax_list: [3]
    mmax_list: null
    grid_resolution: 18
    
    # === DISTANCE & SPATIAL ===
    num_distance_basis: 512
    distance_function: "gaussian"
    max_radius: 12.0
    
    # === MOLECULAR FEATURES ===
    # these are in tokenizer
    # feature_vocab_sizes: null  # Will be set from tokenization features
    # atom_features: ['element', 'charge', 'nhyd', 'hyb']
    # bond_features: ['bond_order', 'is_in_ring', 'is_aromatic']
    embedding_dim: 32
    edge_degree_projector_hidden_layers: 2
    edge_degree_projector_size: 128
    edge_channels_list: null
    
    # === ATTENTION MECHANISMS ===
    use_m_share_rad: False
    attn_activation: "silu"
    use_s2_act_attn: False
    use_attn_renorm: True
    
    # === FEED FORWARD NETWORKS ===
    ffn_activation: "silu"
    use_gate_act: False
    use_grid_mlp: True
    use_sep_s2_act: True
    
    # === REGULARIZATION ===
    alpha_drop: 0.1
    drop_path_rate: 0.1
    proj_drop: 0.0
    weight_init: "uniform"
    
    # === TOPOLOGY GRADIENTS ===
    use_topology_gradients: True
    topology_gradient_clip: 100.0
    
    # === TIME/FILM MODULATION ===
    use_time: False
    film_time_embedding_dim: 128
    film_hidden_dim: 128
    film_mlp_layers: 2
    film_num_gaussians: 512
    film_basis_function: "gaussian"
    
    # # === NORMALIZATION STATISTICS ===
    # avg_num_nodes: 100  # num atoms in the system
    # avg_degree: 20      # eg. the graph size
    
    # === TASK-SPECIFIC PARAMETERS ===    
    # NODE CLASSIFICATION
    node_class_weights: true # the config class expects tensor, here put true or false to use weights from 2.1 script
    node_class_label_smoothing: 0.0
    
    # FILM LOSS
    film_l2_loss_weight: 0.0

    # MANUAL OPERATIONS NEEDED BEFORE INITING THE CONFIG:
    # - get atom and bond features from the tokenizer config
    # - compute feature_vocab_sizes from tokenizer config
    # - if node_class_weights, first extract the values and replace the bool with a tensor.
    # - get avg_degree from the tokenizer config k
    # - get avg_num_nodes from the dataset stats

  accelerate_config: accelerate_configs/one_process_full_precision.yaml

  training:
    # should have 1:1 with TrainingConfig
    max_epochs: 100
    eval_every: 50
    log_every: 10
    max_checkpoints: 5
    save_best_only: True

    lr_initial: 1e-4
    scheduler: "LambdaLR"
    lambda_type: "cosine"
    warmup_epochs: 0
    warmup_factor: 0.2
    lr_min_factor: 0.01
    decay_epochs: null
    decay_rate: 0.1
    
    # Optimization & Regularization  
    optimizer: "AdamW"
    batch_size: 32
    gradient_accumulation_steps: 1
    weight_decay: 0.0
    clip_grad_norm: 1.0
    ema_decay: null
    
    # Reproducibility & Directories
    seed: null
    run_dir: data/2/2.3_pretraining
    overwrite_output_dir: true

    
    # Evaluation
    primary_metric: "val/loss"
    node_level_metrics: False
    
    # Early Stopping
    patience: null
    min_delta: 0.0
    
    # Training Resumption
    resume_from_checkpoint: null
    reset_optimizer: False
    
    # Data Loading & Sampling
    num_workers: 8
    pin_memory: True
    drop_last: True
    shuffle: True
    
    # Advanced Training
    run_val_at_start: True

    